# -*- coding: utf-8 -*-
"""dankmemes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qAw_-_llFu4nQrK6V-CgMCUqAlVJQiKB

**Access to Drive**
"""

#TO DO mount drive
from google.colab import drive
drive.mount("/content/drive")

"""# ***Download Dataset***

**Training Dataset**
"""

import pandas as pd

path = 'drive/My Drive/Colab Notebooks/dankmemes/Dataset/'
csv_data = pd.read_csv(path + 'dankmemes_task_1/dankmemes_task1_train.csv')
embedd_image_train_temp = pd.read_csv(path + 'dankmemes_task_1/dankmemes_task1_train_embeddings.csv')
csv_data = csv_data[["Engagement", "Manipulation", "Visual", "Text", "Meme"]] 

x_train_text_raw = csv_data['Text']
temp_engagement_column_train = csv_data['Engagement']
manipulation_column_train = csv_data['Manipulation']
temp_visual_column_train = csv_data['Visual']

y_train = csv_data["Meme"]

csv_data.head()

"""**Train Images**"""

import matplotlib.pyplot as plt
import cv2
import os

images_path = path + "dankmemes_task_1/images_task1_train/"

plt.figure(figsize=(10,10))

for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    img = cv2.imread(images_path + str(i) + ".jpg")
    plt.imshow(img, cmap=plt.cm.binary)
plt.show()

"""
**Test Dataset**
"""

csv_data_test = pd.read_csv(path+"1_test/meme_test.csv")
embedd_image_test_temp = pd.read_csv(path + '1_test/1_test_embeddings.csv')
csv_data_test = csv_data_test[["Engagement", "Manipulation", "Visual", "Text", "Meme"]] 

x_test_text_raw = csv_data_test['Text']
temp_engagement_column_test = csv_data_test['Engagement']
manipulation_column_test = csv_data_test['Manipulation']
temp_visual_column_test = csv_data_test['Visual']

y_test = csv_data_test["Meme"]

csv_data_test.head()

"""**Test Images**"""

images_path_test = path + "1_test/1_test_img/"

plt.figure(figsize=(10,10))

for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    img = cv2.imread(images_path_test + str(i+4000) + ".jpg")
    plt.imshow(img, cmap=plt.cm.binary)
plt.show()

"""# **Preprocessing**

**Visual Preprocessing**
"""

import tensorflow as tf
from tensorflow import keras
import numpy as np

visual_column = np.concatenate((temp_visual_column_train, temp_visual_column_test))

unique = []

for x in range(len(visual_column)):
  visual_column[x] = visual_column[x].split(', ')
  for k in range(len(visual_column[x])):    
    visual_column[x][k] = visual_column[x][k].lower()

    if len(visual_column[x][k].split(',')) > 1:
      if visual_column[x][k].split(',')[0] != "":
        visual_column[x][k] = visual_column[x][k].split(',')[0]
      else:
        visual_column[x][k] = visual_column[x][k].split(',')[0]

    if visual_column[x][k] not in unique:
      if visual_column[x][k] != "0":
        unique.append(visual_column[x][k])

print("List all of different names:")
print(unique)

visual_column_train = np.zeros((len(temp_visual_column_train), len(unique)))
visual_column_test = np.zeros((len(temp_visual_column_test), len(unique)))
x_visual_test = np.zeros((len(temp_visual_column_test) - 1, len(unique)))

for x in range(len(visual_column)):
  for item in visual_column[x]:
    if item != "0":
      if x < len(temp_visual_column_train):
        visual_column_train[x][unique.index(item)] = 1
      else:
        visual_column_test[x-len(temp_visual_column_train)][unique.index(item)] = 1
        if  x > len(temp_visual_column_train):
          x_visual_test[x-len(temp_visual_column_train) - 1][unique.index(item)] = 1

# x_visual_test = pd.DataFrame(x_visual_test, dtype='int64')

# print()
# visual_column_train = pd.DataFrame(visual_column_train, dtype='int64')
# visual_column_test = pd.DataFrame(visual_column_test, dtype='int64')

print("Visual Training Column:")
print(visual_column_train)
print(len(visual_column_train[1]))
print("")
print("Visual Test Column:")
print(visual_column_test)
print(len(visual_column_test))

"""**Manipulation preprocessing**"""

x_manipulation_test = np.zeros(len(manipulation_column_test) - 1)


for i in range(len(manipulation_column_test)):
  if i > 0:
    x_manipulation_test[i-1] = manipulation_column_test[i]

manipulation_column_train = np.asarray(manipulation_column_train)
manipulation_column_test = np.asarray(manipulation_column_test)
x_manipulation_test = np.asarray(x_manipulation_test)

print(manipulation_column_train.shape)
print(x_manipulation_test.shape)

"""**Engagment Preprocessing**"""

engagement_column = (np.concatenate((temp_engagement_column_train , temp_engagement_column_test)))
max_engage = float(max(engagement_column))

engagement_column_train = []
engagement_column_test = []
x_engagement_test = []

for x in range(len(engagement_column)):
  temp = engagement_column[x] / max_engage
  if x < len(temp_engagement_column_train):
    engagement_column_train.append(temp)
  else:
    engagement_column_test.append(temp)
    if  x > len(temp_engagement_column_train):
        x_engagement_test.append(temp)


engagement_column_train = np.asarray(engagement_column_train)
engagement_column_test = np.asarray(engagement_column_test)
x_engagement_test =np.asarray(x_engagement_test)

print(x_engagement_test.shape)
print("Train Engagement:")
print(engagement_column_train.shape)
print("Test Engagement:")
print(engagement_column_test.shape)

"""**Train Images Preprocessing**"""

dirs = os.listdir(images_path)

train_images = [0 for x in range(len(dirs))]

for item in dirs:
    img = cv2.imread(images_path + item)
    current_image = cv2.resize(img, dsize=(200, 200), interpolation=cv2.INTER_CUBIC)
    # current_image = cv2.cvtColor(current_image, cv2.COLOR_BGR2GRAY)
    data = current_image.astype('float32')
    train_images[int(item.split(".")[0])] = data

train_images = np.asarray(train_images)
train_images = train_images / 255.0

print(train_images.shape)
print(type(train_images))

"""**Embedding Image Train Preprocessing**"""

embedd_image_train_temp = np.asarray(embedd_image_train_temp)

embedd_image_train = [row[1].split(" ") for row in embedd_image_train_temp]
embedd_image_train = np.asarray(embedd_image_train)
embedd_image_train = embedd_image_train.astype('float32')

    
print(embedd_image_train.dtype)
print(embedd_image_train.shape)
# print(embedd_image_train)

"""**Test Images Preprocessing**"""

dirs = os.listdir(images_path_test)

test_images = [0 for x in range(len(dirs))]

for item in dirs:
    img = cv2.imread(images_path_test + item)
    current_image = cv2.resize(img, dsize=(200, 200), interpolation=cv2.INTER_CUBIC)	
    # current_image = cv2.cvtColor(current_image, cv2.COLOR_BGR2GRAY)
    data = current_image.astype('float32')    
    test_images[int(item.split(".")[0]) - 4000] = data

test_images = np.asarray(test_images)
test_images = test_images / 255.0

print(test_images.shape)

"""**Embedding Image Test Preprocessing**"""

embedd_image_test_temp = np.asarray(embedd_image_test_temp)

embedd_image_test = [row[1].split(" ") for row in embedd_image_test_temp]
embedd_image_test = np.asarray(embedd_image_test)
embedd_image_test = embedd_image_test.astype('float32')
y_test_embedd = np.zeros(len(y_test)-1)

for i in range(len(y_test)):
  if i > 0:
    y_test_embedd[i-1] = int(y_test[i])

# y_test_embedd = y_test_embedd.astype(np.int)

print(y_test.shape)
print(y_test_embedd.shape)
print(len(embedd_image_test))
print(embedd_image_test.dtype)
print(embedd_image_test.shape)

"""**Concatenate Features**"""

x_train_features = np.zeros((1600,67))
x_test_features = np.zeros((400,67))
x_test_features_embedd = np.zeros((399,67))

for i in range(len(x_train_features)):
  for k in range(len(x_train_features[i])):
    if k == 0:
      x_train_features[i][k] = engagement_column_train[i]
    if k == 1:
      x_train_features[i][k] = manipulation_column_train[i]
    if k > 1:
      x_train_features[i][k] = visual_column_train[i][k - 2]


for i in range(len(x_test_features)):
  for k in range(len(x_test_features[i])):
    if k == 0:
      x_test_features[i][k] = engagement_column_test[i]
    if k == 1:
      x_test_features[i][k] = manipulation_column_test[i]
    if k > 1:
      x_test_features[i][k] = visual_column_test[i][k - 2]


for i in range(len(x_test_features_embedd)):
  for k in range(len(x_test_features_embedd[i])):
    if k == 0:
      x_test_features_embedd[i][k] = x_engagement_test[i]
    if k == 1:
      x_test_features_embedd[i][k] = x_manipulation_test[i]
    if k > 1:
      x_test_features_embedd[i][k] = x_visual_test[i][k - 2]


print(x_train_features.shape)

print(x_test_features.shape)

print(x_test_features_embedd.shape)

"""**Text Preprocessing**"""

from nltk.tokenize import word_tokenize
import matplotlib.pyplot as pyplot

text_data_raw_train = np.array(x_train_text_raw)
text_data_raw_test = np.array(x_test_text_raw)
text_data_raw = np.concatenate((text_data_raw_train, text_data_raw_test))


tokenizer = keras.preprocessing.text.Tokenizer()
tokenizer.fit_on_texts(text_data_raw)
text_data = tokenizer.texts_to_sequences(text_data_raw)

vocab_size = len(tokenizer.word_index) + 1
print(vocab_size)

x_train_text = text_data[0:1600]
x_test_text = text_data[1600:2000]
x_test_text_embedd = text_data[1601:2000]

max_len = 0
sum_len = 0
count = 0

for item in x_train_text:
  if len(item) > 50:
      count = count + 1
  if len(item) > max_len:
    max_len = len(item)
  sum_len = sum_len + len(item)

print(max_len)
avg_lenghts = sum_len / len(x_train_text)
print("average: " + str(avg_lenghts))
print("Number of lenghts of text > mean: " + str(count) + " the " + str(count*100/len(x_train_text)) + "% of the total")

text_data_max_length = 50
x_train_text = keras.preprocessing.sequence.pad_sequences(sequences=x_train_text, maxlen=text_data_max_length, padding='post')
x_test_text = keras.preprocessing.sequence.pad_sequences(sequences=x_test_text, maxlen=text_data_max_length, padding='post')
x_test_text_embedd = keras.preprocessing.sequence.pad_sequences(sequences=x_test_text_embedd, maxlen=text_data_max_length, padding='post')

print("Train Text: " + str(x_train_text.shape))
print("Test Text: " + str(x_test_text.shape))
print(max_len)

"""**Embedding Matrix**"""

import io

fname = "drive/My Drive/Colab Notebooks/dankmemes/cc.it.300.vec"


# https://fasttext.cc/docs/en/crawl-vectors.html

embedding_dim = 300
embedding_matrix = np.zeros((vocab_size, embedding_dim))
embedding_matrix2 = np.zeros((vocab_size, embedding_dim))
with open(fname, encoding='utf8') as f:
        for line in f:
            word, *vector = line.split()
            if word in tokenizer.word_index:
                idx = tokenizer.word_index[word]
                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]
print(type(embedding_matrix))
print(embedding_matrix.shape)
print(embedding_matrix)

# Check non zero elements
nonzero_elements = np.count_nonzero(np.count_nonzero(embedding_matrix, axis=1))

"""# **Build, train and test of the Models**"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
import sklearn
from sklearn.decomposition import PCA
from matplotlib import pyplot
from sklearn.model_selection import KFold
from tensorflow.keras.losses import sparse_categorical_crossentropy
from tensorflow.keras.optimizers import Adam

from sklearn.metrics import confusion_matrix
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import classification_report

import mlxtend

"""########################################

**Image Model**

########################################

**Build Image Model 1**
"""

kfold = KFold(n_splits=5, shuffle=True)

fold_no = 1
acc_per_fold = []
loss_per_fold = []

for train, test in kfold.split(train_images):

  input_images = keras.layers.Input(shape=(200, 200, 3), name='images')

  y = keras.layers.Conv2D(32, (3,3), activation='relu')(input_images)
  y = keras.layers.MaxPool2D(3,3)(y)
  y =  keras.layers.Dropout(0.25)(y)

  y = keras.layers.Conv2D(32, (3,3), activation='relu')(y)
  y = keras.layers.MaxPool2D(3,3)(y)
  y = keras.layers.Dropout(0.25)(y)

  y = keras.layers.Conv2D(64, (3,3), activation='relu')(y)
  y = keras.layers.MaxPool2D(6)(y)
  y =  keras.layers.Dropout(0.25)(y)

  images_features = keras.layers.Flatten()(y)

  dense = keras.layers.Dense(64)(images_features)
  dense = keras.layers.Dropout(0.25)(dense)
  dense = keras.layers.Dense(4)(dense)
  dense = keras.layers.Dense(1)(dense)
  acti = keras.layers.Activation('sigmoid')(dense)

  func_model_images_1 = keras.Model(input_images, acti)


  if fold_no == 1:
    func_model_images_1.summary()
    
    print('------------------------------------------------------------------------')



  func_model_images_1.compile(optimizer=Adam(),
              loss='binary_crossentropy',
              metrics=['accuracy'])
  
  fold_n = "/fold" + str(fold_no)
  checkpoint_filepath = path + '/tmp/checkpoint_img_1' + fold_n

  metric = 'val_accuracy'
  callback = keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor=metric, mode='max', verbose=1, save_best_only=True)


  print('------------------------------------------------------------------------')
  print(f'Training for fold {fold_no} ...')

  history_1_1 = func_model_images_1.fit(
    x=train_images[train],
    y=y_train[train],
    epochs=25, verbose='auto', 
    validation_data=(train_images[test], y_train[test]), callbacks=[callback])
  
  scores = func_model_images_1.evaluate(train_images[test], y_train[test], verbose=0)
  print(f'Score for fold {fold_no}: {func_model_images_1.metrics_names[0]} of {scores[0]}; {func_model_images_1.metrics_names[1]} of {scores[1]}%')
  acc_per_fold.append(scores[1])
  loss_per_fold.append(scores[0])

  fold_no = fold_no + 1

"""**Cross Validation Image Model 1** """

print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(acc_per_fold)):
  print('------------------------------------------------------------------------')
  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')
print(f'> Loss: {np.mean(loss_per_fold)}')
print('------------------------------------------------------------------------')

"""############################################################

**Build Image Model 2**
"""

kfold = KFold(n_splits=5, shuffle=True)

fold_no = 1
acc_per_fold = []
loss_per_fold = []

for train, test in kfold.split(train_images):

  input_images = keras.layers.Input(shape=(200, 200, 3), name='images')

  y = keras.layers.Conv2D(64, 2, activation='relu')(input_images)
  y = keras.layers.MaxPool2D(8)(y)

  y = keras.layers.Conv2D(128, 2, activation='relu')(y)
  y = keras.layers.MaxPool2D(8)(y)
  y = keras.layers.Dropout(0.3)(y)

  images_features = keras.layers.Flatten()(y)

  dense = keras.layers.Dense(128)(images_features)
  dense = keras.layers.Dropout(0.3)(dense)

  dense = keras.layers.Dense(16)(images_features)
  dense = keras.layers.Dropout(0.3)(dense)

  dense = keras.layers.Dense(1)(dense)

  acti = keras.layers.Activation('sigmoid')(dense)

  func_model_images_2 = keras.Model(input_images, acti)


  if fold_no == 1:
    func_model_images_2.summary()
    
    print('------------------------------------------------------------------------')



  func_model_images_2.compile(optimizer=Adam(),
              loss='binary_crossentropy',
              metrics=['accuracy'])
  
  fold_n = "/fold" + str(fold_no)
  checkpoint_filepath = path + '/tmp/checkpoint_img_2' + fold_n

  metric = 'val_accuracy'
  callback = keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor=metric, mode='max', verbose=1, save_best_only=False)


  print('------------------------------------------------------------------------')
  print(f'Training for fold {fold_no} ...')

  history_1_2 = func_model_images_2.fit(
    x=train_images[train],
    y=y_train[train],
    epochs=20, verbose='auto', 
    validation_data=(train_images[test], y_train[test]), callbacks=[callback])
  
  scores = func_model_images_2.evaluate(train_images[test], y_train[test], verbose=0)
  print(f'Score for fold {fold_no}: {func_model_images_2.metrics_names[0]} of {scores[0]}; {func_model_images_2.metrics_names[1]} of {scores[1]}%')
  acc_per_fold.append(scores[1])
  loss_per_fold.append(scores[0])

  fold_no = fold_no + 1

"""**Cross Validation Image Model 2** """

print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(acc_per_fold)):
  print('------------------------------------------------------------------------')
  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')
print(f'> Loss: {np.mean(loss_per_fold)}')
print('------------------------------------------------------------------------')

"""########################################################

**Build Image Model 3**
"""

kfold = KFold(n_splits=5, shuffle=True)

fold_no = 1
acc_per_fold = []
loss_per_fold = []

for train, test in kfold.split(embedd_image_train):

  input_images = keras.layers.Input(shape=(2048), name='images')

  dense = keras.layers.Dropout(0.7)(input_images)
  dense = keras.layers.Dense(64)(dense)
  dense = keras.layers.Dropout(0.3)(dense)

  dense = keras.layers.Dense(1)(dense)

  acti = keras.layers.Activation('sigmoid')(dense)

  func_model_images_3 = keras.Model(input_images, acti)

  if fold_no == 1:
    func_model_images_3.summary()
    
    print('------------------------------------------------------------------------')



  func_model_images_3.compile(optimizer=Adam(),
              loss='binary_crossentropy',
              metrics=['accuracy'])
  
  fold_n = "/fold" + str(fold_no)
  checkpoint_filepath = path + '/tmp/checkpoint_img_3' + fold_n

  metric = 'val_accuracy'
  callback = keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor=metric, mode='max', verbose=1, save_best_only=True)


  print('------------------------------------------------------------------------')
  print(f'Training for fold {fold_no} ...')

  history_1_3 = func_model_images_3.fit(embedd_image_train[train],y_train[train],
    validation_data=(embedd_image_train[test],y_train[test]),
    epochs=50, verbose='auto', 
    callbacks=[callback])
  
  scores = func_model_images_3.evaluate(embedd_image_train[test], y_train[test], verbose=0)
  print(f'Score for fold {fold_no}: {func_model_images_3.metrics_names[0]} of {scores[0]}; {func_model_images_3.metrics_names[1]} of {scores[1]}')
  acc_per_fold.append(scores[1])
  loss_per_fold.append(scores[0])

  fold_no = fold_no + 1

"""**Cross Validation Image model 3** """

print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(acc_per_fold)):
  print('------------------------------------------------------------------------')
  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')
print(f'> Loss: {np.mean(loss_per_fold)}')
print('------------------------------------------------------------------------')

"""########################################################################

**Plot Image Model 1**
"""

print(history_1_1.history.keys())

pyplot.plot(history_1_1.history['accuracy'])
pyplot.plot(history_1_1.history['val_accuracy'])
pyplot.title('model accuracy')
pyplot.ylabel('accuracy')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

pyplot.plot(history_1_1.history['loss'])
pyplot.plot(history_1_1.history['val_loss'])
pyplot.title('model loss')
pyplot.ylabel('loss')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

"""**Plot Image Model 2**"""

print(history_1_2.history.keys())

pyplot.plot(history_1_2.history['accuracy'])
pyplot.plot(history_1_2.history['val_accuracy'])
pyplot.title('model accuracy')
pyplot.ylabel('accuracy')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

pyplot.plot(history_1_2.history['loss'])
pyplot.plot(history_1_2.history['val_loss'])
pyplot.title('model loss')
pyplot.ylabel('loss')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

"""**Plot Image Model 3**"""

print(history_1_3.history.keys())

pyplot.plot(history_1_3.history['accuracy'])
pyplot.plot(history_1_3.history['val_accuracy'])
pyplot.title('model accuracy')
pyplot.ylabel('accuracy')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

pyplot.plot(history_1_3.history['loss'])
pyplot.plot(history_1_3.history['val_loss'])
pyplot.title('model loss')
pyplot.ylabel('loss')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

"""#################################################################

**Train Best Image Model**
"""

input_images = keras.layers.Input(shape=(2048), name='images')

dense = keras.layers.Dropout(0.7)(input_images)
dense = keras.layers.Dense(64)(dense)
dense = keras.layers.Dropout(0.3)(dense)

dense = keras.layers.Dense(1)(dense)

acti = keras.layers.Activation('sigmoid')(dense)

func_model_images = keras.Model(input_images, acti)

func_model_images.summary()
    
print('------------------------------------------------------------------------')


func_model_images.compile(optimizer=Adam(),
            loss='binary_crossentropy',
            metrics=['accuracy'])
  
checkpoint_filepath = path + '/tmp/checkpoint_img'

metric = 'accuracy'
callback = keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor=metric, mode='max', verbose=1, save_best_only=True)


print('------------------------------------------------------------------------')

history_1 = func_model_images.fit(embedd_image_train,y_train,
  epochs=8, verbose='auto', 
  callbacks=[callback])

"""**Test Best Image Model**"""

model = keras.models.load_model(path + '/tmp/checkpoint_img')


predictions = model.predict({'images': embedd_image_test}, verbose=1)
data = []
i = 0
for prediction in predictions:
    temp = 0
    if prediction >= 0.5:
        temp = 1
    data.append(temp)
    i = i + 1

mat = confusion_matrix(y_test_embedd, data)

print()

plot_confusion_matrix(conf_mat=mat, figsize=(3, 3), show_normed=True)

accuracy = sklearn.metrics.accuracy_score(y_test_embedd, data)
print('Accuracy: %f' % accuracy)

precision = sklearn.metrics.precision_score(y_test_embedd, data)
print('Precision: %f' % precision)

recall = sklearn.metrics.recall_score(y_test_embedd, data)
print('Recall: %f' % recall)

f1 = sklearn.metrics.f1_score(y_test_embedd, data)
print('F1 score: %f' % f1)


print()
print("Confusion matrix:")
mat = confusion_matrix(y_test_embedd, data)

"""########################################

**Features Model**

########################################

**Build Featuras Model 1**
"""

kfold = KFold(n_splits=5, shuffle=True)

fold_no = 1
acc_per_fold = []
loss_per_fold = []



for train, test in kfold.split(engagement_column_train):

  input_text = keras.layers.Input(shape=(text_data_max_length, ), name='text')
  input_features = keras.layers.Input(shape=(67,), name='features')

  text_embed = keras.layers.Embedding(vocab_size, embedding_dim,
                                weights=[embedding_matrix], 
                                input_length=text_data_max_length, 
                                trainable=False)(input_text)

  x = keras.layers.SpatialDropout1D(0.5)(text_embed)

  x = keras.layers.Conv1D(32, 3, activation='relu')(x)
  x = keras.layers.MaxPooling1D(pool_size=5)(x)


  text_features = keras.layers.Flatten()(x)

  conc = keras.layers.concatenate([text_features, input_features])

  dense = keras.layers.Dropout(0.5)(conc)
  dense = keras.layers.Dense(64)(dense)
  dense = keras.layers.Dropout(0.3)(dense)


  dense = keras.layers.Dense(1)(dense)

  acti = keras.layers.Activation('sigmoid')(dense)

  func_model_features_1 = keras.Model([input_text, input_features], acti)


  if fold_no == 1:
    func_model_features_1.summary()
    
    print('------------------------------------------------------------------------')



  func_model_features_1.compile(optimizer=Adam(),
              loss='binary_crossentropy',
              metrics=['accuracy'])
  
  fold_n = "/fold" + str(fold_no)
  checkpoint_filepath = path + '/tmp/checkpoint_feat_1' + fold_n

  metric = 'val_accuracy'
  callback = keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor=metric, mode='max', verbose=1, save_best_only=False)


  print('------------------------------------------------------------------------')
  print(f'Training for fold {fold_no} ...')

  history_2_1 = func_model_features_1.fit(
    x={'text':x_train_text[train], 'features':x_train_features[train]},
    y=y_train[train],
    epochs=10, verbose='auto', 
    validation_data=({'text':x_train_text[test], 'features':x_train_features[test]}, y_train[test]), callbacks=[callback])
  
  scores = func_model_features_1.evaluate({'text':x_train_text[test], 'features':x_train_features[test]}, y_train[test], verbose=0)
  print(f'Score for fold {fold_no}: {func_model_features_1.metrics_names[0]} of {scores[0]}; {func_model_features_1.metrics_names[1]} of {scores[1]}')
  acc_per_fold.append(scores[1])
  loss_per_fold.append(scores[0])

  fold_no = fold_no + 1

"""**Cross Validation Featuras Model 1**"""

print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(acc_per_fold)):
  print('------------------------------------------------------------------------')
  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')
print(f'> Loss: {np.mean(loss_per_fold)}')
print('------------------------------------------------------------------------')

"""####################################################################

**Build Features 2**
"""

kfold = KFold(n_splits=5, shuffle=True)

fold_no = 1
acc_per_fold = []
loss_per_fold = []



for train, test in kfold.split(engagement_column_train):

  input_text = keras.layers.Input(shape=(text_data_max_length, ), name='text')
  input_features = keras.layers.Input(shape=(67,), name='features')

  text_embed = keras.layers.Embedding(vocab_size, embedding_dim,
                                weights=[embedding_matrix], 
                                input_length=text_data_max_length, 
                                trainable=False)(input_text)

  x = keras.layers.SpatialDropout1D(0.2)(text_embed)

  x = keras.layers.Conv1D(16, 3, activation='relu')(x)
  x = keras.layers.MaxPooling1D(pool_size=10)(x)

  x = keras.layers.Conv1D(16, 3, activation='relu')(x)
  x = keras.layers.MaxPooling1D(pool_size=2)(x)

  text_features = keras.layers.Flatten()(x)

  conc = keras.layers.concatenate([text_features, input_features])

  dense = keras.layers.Dropout(0.5)(conc)
  dense = keras.layers.Dense(16)(dense)
  dense = keras.layers.Dropout(0.3)(dense)


  dense = keras.layers.Dense(1)(dense)

  acti = keras.layers.Activation('sigmoid')(dense)

  func_model_features_2 = keras.Model([input_text, input_features], acti)


  if fold_no == 1:
    func_model_features_2.summary()
    
    print('------------------------------------------------------------------------')



  func_model_features_2.compile(optimizer=Adam(),
              loss='binary_crossentropy',
              metrics=['accuracy'])
  
  fold_n = "/fold" + str(fold_no)
  checkpoint_filepath = path + '/tmp/checkpoint_feat_2' + fold_n

  metric = 'val_accuracy'
  callback = keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor=metric, mode='max', verbose=1, save_best_only=False)


  print('------------------------------------------------------------------------')
  print(f'Training for fold {fold_no} ...')

  history_2_2 = func_model_features_2.fit(
    x={'text':x_train_text[train], 'features':x_train_features[train]},
    y=y_train[train],
    epochs=12, verbose='auto', 
    validation_data = ({'text':x_train_text[test], 'features':x_train_features[test]}, y_train[test]), callbacks=[callback])
  
  scores = func_model_features_2.evaluate({'text':x_train_text[test], 'features':x_train_features[test]}, y_train[test], verbose=0)
  print(f'Score for fold {fold_no}: {func_model_features_2.metrics_names[0]} of {scores[0]}; {func_model_features_2.metrics_names[1]} of {scores[1]}%')
  acc_per_fold.append(scores[1])
  loss_per_fold.append(scores[0])

  fold_no = fold_no + 1

"""**Cross Validation Features Model 2**"""

print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(acc_per_fold)):
  print('------------------------------------------------------------------------')
  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')
print(f'> Loss: {np.mean(loss_per_fold)}')
print('------------------------------------------------------------------------')

"""###################################################################

**Plot Features Model 1**
"""

print(history_2_1.history.keys())

pyplot.plot(history_2_1.history['accuracy'])
pyplot.plot(history_2_1.history['val_accuracy'])
pyplot.title('model accuracy')
pyplot.ylabel('accuracy')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

pyplot.plot(history_2_1.history['loss'])
pyplot.plot(history_2_1.history['val_loss'])
pyplot.title('model loss')
pyplot.ylabel('loss')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

"""**Plot Features Model 2**"""

print(history_2_2.history.keys())

pyplot.plot(history_2_2.history['accuracy'])
pyplot.plot(history_2_2.history['val_accuracy'])
pyplot.title('model accuracy')
pyplot.ylabel('accuracy')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

pyplot.plot(history_2_2.history['loss'])
pyplot.plot(history_2_2.history['val_loss'])
pyplot.title('model loss')
pyplot.ylabel('loss')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

"""####################################################################

**Train Best Features Model**
"""

input_text = keras.layers.Input(shape=(text_data_max_length, ), name='text')
input_features = keras.layers.Input(shape=(67,), name='features')

text_embed = keras.layers.Embedding(vocab_size, embedding_dim,
                                weights=[embedding_matrix], 
                                input_length=text_data_max_length, 
                                trainable=False)(input_text)

x = keras.layers.SpatialDropout1D(0.5)(text_embed)

x = keras.layers.Conv1D(32, 3, activation='relu')(x)
x = keras.layers.MaxPooling1D(pool_size=5)(x)


text_features = keras.layers.Flatten()(x)

conc = keras.layers.concatenate([text_features, input_features])

dense = keras.layers.Dropout(0.5)(conc)
dense = keras.layers.Dense(64)(dense)
dense = keras.layers.Dropout(0.3)(dense)

dense = keras.layers.Dense(1)(dense)

acti = keras.layers.Activation('sigmoid')(dense)

func_model_features = keras.Model([input_text, input_features], acti)



func_model_features.summary()
    
print('------------------------------------------------------------------------')


func_model_features.compile(optimizer=Adam(),
            loss='binary_crossentropy',
            metrics=['accuracy'])

checkpoint_filepath = path + '/tmp/checkpoint_feat'

metric = 'accuracy'
callback = keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor=metric, mode='max', verbose=1, save_best_only=False)


print('------------------------------------------------------------------------')

history_2 = func_model_features.fit(
  x={'text':x_train_text, 'features':x_train_features},
  y=y_train,
  epochs=12, verbose='auto', 
  callbacks=[callback])

"""**Test Best Features Model**"""

model = keras.models.load_model(path + '/tmp/checkpoint_feat')

x_test_text = np.array(x_test_text)


predictions = model.predict(x={"text":x_test_text, "features":x_test_features}, verbose=1)
data = []
i = 0
for prediction in predictions:
    temp = 0
    if prediction >= 0.5:
        temp = 1
    data.append(temp)
    i = i + 1


mat = confusion_matrix(y_test, data)

print()

plot_confusion_matrix(conf_mat=mat, figsize=(3, 3), show_normed=True)

accuracy = sklearn.metrics.accuracy_score(y_test, data)
print('Accuracy: %f' % accuracy)

precision = sklearn.metrics.precision_score(y_test, data)
print('Precision: %f' % precision)

recall = sklearn.metrics.recall_score(y_test, data)
print('Recall: %f' % recall)

f1 = sklearn.metrics.f1_score(y_test, data)
print('F1 score: %f' % f1)


print()
print("Confusion matrix:")
mat = confusion_matrix(y_test, data)

"""########################################

**Image + features Model**

########################################

**Build Final Model 1**
"""

kfold = KFold(n_splits=5, shuffle=True)

fold_no = 1
acc_per_fold = []
loss_per_fold = []


for train, test in kfold.split(x_train_features):

  input_text = keras.layers.Input(shape=(text_data_max_length, ), name='text')
  input_features = keras.layers.Input(shape=(67,), name='features')
  input_images = keras.layers.Input(shape=(2048), name='images')

  text_embed = keras.layers.Embedding(vocab_size, embedding_dim,
                                weights=[embedding_matrix], 
                                input_length=text_data_max_length, 
                                trainable=False)(input_text)

  x = keras.layers.SpatialDropout1D(0.5)(text_embed)

  x = keras.layers.Conv1D(24, 3, activation='relu')(x)
  x = keras.layers.MaxPooling1D(pool_size=5)(x)


  text_features = keras.layers.Flatten()(x)

  images = keras.layers.Dropout(0.7)(input_images)
  images = keras.layers.Dense(128)(images)
  images = keras.layers.Dropout(0.2)(images)

  features = keras.layers.Dropout(0.2)(input_features)
  features = keras.layers.Dense(4)(features)

  conc = keras.layers.concatenate([text_features, features, images])

  dense = keras.layers.Dropout(0.4)(conc)
  dense = keras.layers.Dense(32)(dense)
  dense = keras.layers.Dropout(0.2)(dense)

  dense = keras.layers.Dense(4)(dense)
  dense = keras.layers.Dropout(0.2)(dense)

  dense = keras.layers.Dense(1)(dense)

  acti = keras.layers.Activation('sigmoid')(dense)

  func_model_final_1 = keras.Model([input_text, input_features,input_images], acti)


  if fold_no == 1:
    func_model_final_1.summary()    
    print('------------------------------------------------------------------------')



  func_model_final_1.compile(optimizer=Adam(),
              loss='binary_crossentropy',
              metrics=['accuracy'])
  
  fold_n = "/fold" + str(fold_no)
  checkpoint_filepath = path + '/tmp/checkpoint_final_1' + fold_n

  metric = 'val_accuracy'
  callback = keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor=metric, mode='max', verbose=1, save_best_only=False)


  print('------------------------------------------------------------------------')
  print(f'Training for fold {fold_no} ...')

  history_3_1 = func_model_final_1.fit(
    x={'text':x_train_text[train], 'features':x_train_features[train], 'images':embedd_image_train[train]},
    y=y_train[train],
    epochs=35, verbose='auto', 
    validation_data=({'text':x_train_text[test], 'features':x_train_features[test], 'images':embedd_image_train[test]}, y_train[test]), callbacks=[callback])
  
  scores = func_model_final_1.evaluate({'text':x_train_text[test], 'features':x_train_features[test], 'images':embedd_image_train[test]}, y_train[test], verbose=0)
  print(f'Score for fold {fold_no}: {func_model_final_1.metrics_names[0]} of {scores[0]}; {func_model_final_1.metrics_names[1]} of {scores[1]}')
  acc_per_fold.append(scores[1])
  loss_per_fold.append(scores[0])

  fold_no = fold_no + 1

"""**Cross Validation Final Model 1**"""

print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(acc_per_fold)):
  print('------------------------------------------------------------------------')
  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')
print(f'> Loss: {np.mean(loss_per_fold)}')
print('------------------------------------------------------------------------')

"""**Build Final Model 2**

"""

kfold = KFold(n_splits=5, shuffle=True)

fold_no = 1
acc_per_fold = []
loss_per_fold = []



for train, test in kfold.split(x_train_features):

  input_text = keras.layers.Input(shape=(text_data_max_length, ), name='text')
  input_features = keras.layers.Input(shape=(67,), name='features')
  input_images = keras.layers.Input(shape=(2048), name='images')

  text_embed = keras.layers.Embedding(vocab_size, embedding_dim,
                                weights=[embedding_matrix], 
                                input_length=text_data_max_length, 
                                trainable=False)(input_text)

  x = keras.layers.SpatialDropout1D(0.5)(text_embed)

  x = keras.layers.Conv1D(16, 3, activation='relu')(x)
  x = keras.layers.MaxPooling1D(pool_size=10)(x)


  text = keras.layers.Flatten()(x)


  conc = keras.layers.concatenate([text, input_features, input_images])

  dense = keras.layers.Dropout(0.6)(conc) 
  dense = keras.layers.Dense(256)(dense)
  dense = keras.layers.Dropout(0.2)(dense)

  # dense = keras.layers.Dense(32)(dense)
  # dense = keras.layers.Dropout(0.2)(dense)

  dense = keras.layers.Dense(16)(dense)
  dense = keras.layers.Dropout(0.2)(dense)

  dense = keras.layers.Dense(1)(dense)

  acti = keras.layers.Activation('sigmoid')(dense)

  func_model_final_2 = keras.Model([input_text, input_features,input_images], acti)


  if fold_no == 1:
    func_model_final_2.summary()    
    print('------------------------------------------------------------------------')


  func_model_final_2.compile(optimizer=Adam(),
              loss='binary_crossentropy',
              metrics=['accuracy'])
  
  fold_n = "/fold" + str(fold_no)
  checkpoint_filepath = path + '/tmp/checkpoint_final_2' + fold_n

  metric = 'val_accuracy'
  callback = keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor=metric, mode='max', verbose=1, save_best_only=False)


  print('------------------------------------------------------------------------')
  print(f'Training for fold {fold_no} ...')

  history_3_2 = func_model_final_2.fit(
    x={'text':x_train_text[train], 'features':x_train_features[train], 'images':embedd_image_train[train]},
    y=y_train[train],
    epochs=35, verbose='auto', 
    validation_data=({'text':x_train_text[test], 'features':x_train_features[test], 'images':embedd_image_train[test]}, y_train[test]), callbacks=[callback])
  
  scores = func_model_final_2.evaluate({'text':x_train_text[test], 'features':x_train_features[test], 'images':embedd_image_train[test]}, y_train[test], verbose=0)
  print(f'Score for fold {fold_no}: {func_model_final_2.metrics_names[0]} of {scores[0]}; {func_model_final_2.metrics_names[1]} of {scores[1]}')
  acc_per_fold.append(scores[1])
  loss_per_fold.append(scores[0])

  fold_no = fold_no + 1

"""**Cross Validation Final Model 2**"""

print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(acc_per_fold)):
  print('------------------------------------------------------------------------')
  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')
print(f'> Loss: {np.mean(loss_per_fold)}')
print('------------------------------------------------------------------------')

"""**Plot Final Model 1**"""

print(history_3_1.history.keys())

pyplot.plot(history_3_1.history['accuracy'])
pyplot.plot(history_3_1.history['val_accuracy'])
pyplot.title('model accuracy')
pyplot.ylabel('accuracy')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

pyplot.plot(history_3_1.history['loss'])
pyplot.plot(history_3_1.history['val_loss'])
pyplot.title('model loss')
pyplot.ylabel('loss')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

"""**Plot Final Model 2**"""

print(history_3_2.history.keys())

pyplot.plot(history_3_2.history['accuracy'])
pyplot.plot(history_3_2.history['val_accuracy'])
pyplot.title('model accuracy')
pyplot.ylabel('accuracy')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

pyplot.plot(history_3_2.history['loss'])
pyplot.plot(history_3_2.history['val_loss'])
pyplot.title('model loss')
pyplot.ylabel('loss')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'validation'], loc='upper left')
pyplot.show()

"""**Train Best Final Model**"""

input_text = keras.layers.Input(shape=(text_data_max_length, ), name='text')
input_features = keras.layers.Input(shape=(67,), name='features')
input_images = keras.layers.Input(shape=(2048), name='images')

text_embed = keras.layers.Embedding(vocab_size, embedding_dim,
                                weights=[embedding_matrix], 
                                input_length=text_data_max_length, 
                                trainable=False)(input_text)

x = keras.layers.SpatialDropout1D(0.5)(text_embed)

x = keras.layers.Conv1D(24, 3, activation='relu')(x)
x = keras.layers.MaxPooling1D(pool_size=5)(x)


text_features = keras.layers.Flatten()(x)

images = keras.layers.Dropout(0.7)(input_images)
images = keras.layers.Dense(128)(images)
images = keras.layers.Dropout(0.2)(images)

features = keras.layers.Dropout(0.2)(input_features)
features = keras.layers.Dense(4)(features)

conc = keras.layers.concatenate([text_features, features, images])

dense = keras.layers.Dropout(0.4)(conc)
dense = keras.layers.Dense(32)(dense)
dense = keras.layers.Dropout(0.2)(dense)

dense = keras.layers.Dense(4)(dense)
dense = keras.layers.Dropout(0.2)(dense)

dense = keras.layers.Dense(1)(dense)

acti = keras.layers.Activation('sigmoid')(dense)

func_model_final = keras.Model([input_text, input_features,input_images], acti)



func_model_final.summary()    
print('------------------------------------------------------------------------')



func_model_final.compile(optimizer=Adam(),
            loss='binary_crossentropy',
            metrics=['accuracy'])
  

checkpoint_filepath = path + '/tmp/checkpoint_final'

metric = 'accuracy'
callback = keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor=metric, mode='max', verbose=1, save_best_only=False)

print('------------------------------------------------------------------------')
print(f'Training for fold {fold_no} ...')

history_3_1 = func_model_final.fit(
  x={'text':x_train_text, 'features':x_train_features, 'images':embedd_image_train},
  y=y_train,
  epochs=35, verbose='auto', 
  callbacks=[callback])

"""**Test Best Final Model**"""

del = keras.models.load_model(path + '/tmp/checkpoint_final')


x_test_text = np.array(x_test_text)

predictions = model.predict({"text":x_test_text_embedd, "features":x_test_features_embedd,'images': embedd_image_test}, verbose=1)
data = []
i = 0
for prediction in predictions:
    temp = 0
    if prediction >= 0.5:
        temp = 1
    data.append(temp)
    i = i + 1

mat = confusion_matrix(y_test_embedd, data)

print()

plot_confusion_matrix(conf_mat=mat, figsize=(3, 3), show_normed=True)

accuracy = sklearn.metrics.accuracy_score(y_test_embedd, data)
print('Accuracy: %f' % accuracy)

precision = sklearn.metrics.precision_score(y_test_embedd, data)
print('Precision: %f' % precision)

recall = sklearn.metrics.recall_score(y_test_embedd, data)
print('Recall: %f' % recall)

f1 = sklearn.metrics.f1_score(y_test_embedd, data)
print('F1 score: %f' % f1)


print()
print("Confusion matrix:")
mat = confusion_matrix(y_test_embedd, data)